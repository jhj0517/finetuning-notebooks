{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "ðŸ“Œ **This notebook has been updated in [jhj0517/finetuning-notebooks](https://github.com/jhj0517/finetuning-notebooks) repository!**\n",
        "\n",
        "## Version : 1.0.0\n",
        "---"
      ],
      "metadata": {
        "id": "doKhBBXIfS21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #(Optional) Check GPU\n",
        "\n",
        "#@markdown To train SDXL lora at least 12GB VRAM is recommended.\n",
        "#@markdown <br>You can check your GPU setup before start.\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "23yZvUlagEsx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNbSbsctxahq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title #1. Install Dependencies\n",
        "#@markdown This notebook is powered by https://github.com/huggingface/diffusers\n",
        "!git clone https://github.com/huggingface/diffusers\n",
        "%cd diffusers\n",
        "!pip install -e .\n",
        "\n",
        "# Cherry picked dependencies from https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/requirements_sdxl.txt to use in Colab.\n",
        "!pip install ftfy\n",
        "!pip install datasets\n",
        "!pip install bitsandbytes\n",
        "# Only install this if you want to use optimization with xformers.\n",
        "# !pip install xformers\n",
        "\n",
        "\n",
        "# Comment on the requirements above, and uncomment below if you're not using Colab.\n",
        "# !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126\n",
        "# !pip install deepspeed\n",
        "# !pip install accelerate>=0.22.0\n",
        "# !pip install transformers>=4.25.1\n",
        "# !pip install ftfy\n",
        "# !pip install tensorboard\n",
        "# !pip install Jinja2\n",
        "# !pip install datasets\n",
        "# !pip install peft==0.7.0\n",
        "# !pip install xformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 2. (Optional) Mount Google Drive\n",
        "\n",
        "#@markdown It's not mandatory but it's recommended to mount to Google Drive and use the Google Drive's path for your training image dataset.\n",
        "\n",
        "#@markdown The dataset should have following structure:\n",
        "\n",
        "#@markdown This notebook uses diffuser's dreambooth LoRA training, you only need image files in the dataset with this way.\n",
        "\n",
        "#@markdown ### Example File Structure (Image Files Only):\n",
        "#@markdown ```\n",
        "#@markdown your-dataset/\n",
        "#@markdown â”œâ”€â”€ a (1).png         # Image file\n",
        "#@markdown â”œâ”€â”€ a (2).png         # Another image file\n",
        "#@markdown â”œâ”€â”€ a (3).png         # Another image file\n",
        "#@markdown ```\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M1bu3MpsACOu",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a179c7-8249-43d2-bca3-256a36cf96b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 3. (Optional) Register Huggingface Token To Download Base Model\n",
        "\n",
        "#@markdown If you don't have entire base model files ([stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main)) in the drive you need to sign in to Huggingface to download the model.\n",
        "\n",
        "#@markdown Get your tokens from https://huggingface.co/settings/tokens, and register it in colab's seceret as **`HF_TOKEN`** and use it in any notebook. ( 'Read' permission is enough )\n",
        "\n",
        "#@markdown To register secrets in colab, click on the key-shaped icon in the left panel and enter your **`HF_TOKEN`** like this:\n",
        "\n",
        "#@markdown ![image](https://media.githubusercontent.com/media/jhj0517/finetuning-notebooks/master/docs/screenshots/colab_secrets.png)\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "print(\"HF_TOKEN environment variable has been set.\")"
      ],
      "metadata": {
        "id": "9WzQRwZij5jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900c2f41-f2df-47f7-85ef-237b435cede2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN environment variable has been set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 4. Train with Parameters\n",
        "import os\n",
        "import toml\n",
        "import json\n",
        "import re\n",
        "\n",
        "#@markdown ## Paths Configuration\n",
        "DATASET_DIR = \"/content/drive/MyDrive/finetuning-notebooks/dataset/dog-dreambooth\" # @param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/finetuning-notebooks/sdxl/outputs\" # @param {type:\"string\"}\n",
        "OUTPUT_NAME = \"My-SDXL-LoRA-V1\" # @param {type:\"string\"}\n",
        "\n",
        "OUTPUT_DIR = os.path.join(OUTPUT_DIR, OUTPUT_NAME)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "#@markdown ## Base Model Configuration\n",
        "BASE_MODEL_PATH_OR_ID = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param {type:\"string\"}\n",
        "BASE_VAE_PATH_OR_ID = \"madebyollin/sdxl-vae-fp16-fix\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Dataset Configuration\n",
        "# CAPTION_EXTENSION = \".txt\" # @param {type:\"string\"}\n",
        "RESOLUTION = 1024 # @param {type:\"integer\"}\n",
        "# CAPTION_COLUMN = \"text\"\n",
        "\n",
        "#@markdown ## Training Settings\n",
        "MIXED_PRECISION = \"bf16\" # @param [\"no\", \"fp16\", \"bf16\"]\n",
        "INSTANCE_PROMPT = \"A sks dog\" # @param {type:\"string\"}\n",
        "RANDOM_FLIP = True # @param {type:\"boolean\"}\n",
        "TRAIN_BATCH_SIZE = 1 # @param {type:\"integer\"}\n",
        "MAX_TRAIN_STEPS = 500 # @param {type:\"integer\"}\n",
        "CHECKPOINTING_STEPS = 1 # @param {type:\"integer\"}\n",
        "LEARNING_RATE = 1e-4 # @param {type:\"number\"}\n",
        "LR_SCHEDULER = \"constant\" # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n",
        "LR_WARMUP_STEPS = 0 # @param {type:\"integer\"}\n",
        "GRADIENT_ACCUMULATION_STEPS = 4 # @param {type:\"integer\"}\n",
        "SEED = 77 # @param {type:\"integer\"}\n",
        "GRADIENT_CHECKPOINTING = True # @param {type:\"boolean\"}\n",
        "USE_8_BIT_ADAM = True # @param {type:\"boolean\"}\n",
        "# ENABLE_XFORMERS_MEMORY_EFFICIENT_ATTENTION = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ## Network Settings\n",
        "RANK = 4 # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#@markdown ## Validation Configuration\n",
        "#@markdown WandB is a 3rd party service, to use it you need to get an API key from https://wandb.ai/authorize.\n",
        "ENABLE_WANDB = False # @param {type:\"boolean\"}\n",
        "VALIDATION_PROMPT = \"A sks dog is playing with a ball in grass\"  # @param {type:\"string\"}\n",
        "# NUM_VALIDATION_IMAGES = 4 # @param {type:\"integer\"}\n",
        "VALIDATION_EPOCHS = 25 # @param {type:\"integer\"}\n",
        "\n",
        "# Write Command\n",
        "command_parts = [\n",
        "    \"accelerate\", \"launch\",\n",
        "    \"\\\"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py\\\"\",\n",
        "]\n",
        "\n",
        "command_parts.extend([\n",
        "    f\"--pretrained_model_name_or_path=\\\"{BASE_MODEL_PATH_OR_ID}\\\"\",\n",
        "    f\"--pretrained_vae_model_name_or_path=\\\"{BASE_VAE_PATH_OR_ID}\\\"\",\n",
        "    f\"--instance_data_dir=\\\"{DATASET_DIR}\\\"\",\n",
        "    f\"--instance_prompt=\\\"{INSTANCE_PROMPT}\\\"\",\n",
        "#    f\"--caption_column={CAPTION_COLUMN}\",\n",
        "    f\"--mixed_precision={MIXED_PRECISION}\",\n",
        "    f\"--resolution={RESOLUTION}\",\n",
        "    f\"--max_train_steps={MAX_TRAIN_STEPS}\",\n",
        "    f\"--train_batch_size={TRAIN_BATCH_SIZE}\",\n",
        "    f\"--checkpointing_steps={CHECKPOINTING_STEPS}\",\n",
        "    f\"--learning_rate={LEARNING_RATE}\",\n",
        "    f\"--lr_scheduler={LR_SCHEDULER}\",\n",
        "    f\"--lr_warmup_steps={LR_WARMUP_STEPS}\",\n",
        "    f\"--seed={SEED}\",\n",
        "    f\"--output_dir={OUTPUT_DIR}\",\n",
        "    f\"--validation_prompt=\\\"{VALIDATION_PROMPT}\\\"\",\n",
        "#    f\"--num_validation_images={NUM_VALIDATION_IMAGES}\",\n",
        "    f\"--validation_epochs={VALIDATION_EPOCHS}\",\n",
        "    f\"--gradient_accumulation_steps={GRADIENT_ACCUMULATION_STEPS}\",\n",
        "    f\"--rank={RANK}\",\n",
        "\n",
        "])\n",
        "\n",
        "if RANDOM_FLIP:\n",
        "    command_parts.append(\"--random_flip\")\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    command_parts.append(\"--report_to=\\\"wandb\\\"\")\n",
        "\n",
        "if GRADIENT_CHECKPOINTING:\n",
        "    command_parts.append(\"--gradient_checkpointing\")\n",
        "\n",
        "if USE_8_BIT_ADAM:\n",
        "    command_parts.append(\"--use_8bit_adam\")\n",
        "\n",
        "# if ENABLE_XFORMERS_MEMORY_EFFICIENT_ATTENTION:\n",
        "#     command_parts.append(\"--enable_xformers_memory_efficient_attention\")\n",
        "\n",
        "# Write metadata.jsonl for the dataset\n",
        "def create_metadata_jsonl(dataset_dir, caption_extension=\".txt\"):\n",
        "    metadata = []\n",
        "    image_files = [f for f in os.listdir(dataset_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        base_name = os.path.splitext(image_file)[0]\n",
        "        caption_file = f\"{base_name}{caption_extension}\"\n",
        "\n",
        "        if os.path.exists(os.path.join(dataset_dir, caption_file)):\n",
        "            try:\n",
        "                with open(os.path.join(dataset_dir, caption_file), \"r\", encoding=\"utf-8\") as f:\n",
        "                    caption = f.read().strip()\n",
        "\n",
        "                match = re.search(r\"\\((\\d+)\\)\", base_name)\n",
        "                if match:\n",
        "                    file_number = int(match.group(1))\n",
        "                    new_file_name = f\"{file_number:04d}.png\"\n",
        "                else:\n",
        "                    file_number = len(metadata) + 1\n",
        "                    new_file_name = f\"{file_number:04d}.png\"\n",
        "\n",
        "                metadata.append({\"file_name\": new_file_name, \"text\": caption})\n",
        "\n",
        "                os.rename(os.path.join(dataset_dir, image_file), os.path.join(dataset_dir, new_file_name))\n",
        "                os.rename(os.path.join(dataset_dir, caption_file), os.path.join(dataset_dir, f\"{file_number:04d}{caption_extension}\"))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_file}: {e}\")\n",
        "        else:\n",
        "            print(f\"Warning: Caption file {caption_file} not found for {image_file}\")\n",
        "\n",
        "    metadata_path = os.path.join(dataset_dir, \"metadata.jsonl\")\n",
        "    with open(metadata_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "        for item in metadata:\n",
        "            json.dump(item, outfile, ensure_ascii=False)\n",
        "            outfile.write(\"\\n\")\n",
        "\n",
        "# Diffuser's script does not use each caption with dreambooth.\n",
        "# create_metadata_jsonl(DATASET_DIR, CAPTION_EXTENSION)\n",
        "# print(f\"{os.path.join(DATASET_DIR, 'metadata.jsonl')} has written.\")\n",
        "\n",
        "# Train\n",
        "!accelerate config default\n",
        "command = \" \".join(command_parts)\n",
        "print(command)\n",
        "!{command}"
      ],
      "metadata": {
        "id": "fob2cRMQeW5C",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # 5. (Optional) Test your LoRA\n",
        "\n",
        "from huggingface_hub.repocard import RepoCard\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "BASE_MODEL_PATH_OR_ID = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param {type:\"string\"}\n",
        "YOUR_LORA_PATH = \"/content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/something/pytorch_lora_weights.safetensors\" # @param {type:\"string\"}\n",
        "PROMPT = \"A picture of a sks dog in a bucket\" # @param {type:\"string\"}\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(BASE_MODEL_PATH_OR_ID, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(YOUR_LORA_PATH)\n",
        "image = pipe(PROMPT, num_inference_steps=25).images[0]\n",
        "image.save(\"sks_dog.png\")\n",
        "\n",
        "from IPython.display import display\n",
        "display(image)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PALmQfvtSk6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}