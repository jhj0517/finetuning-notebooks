{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "ðŸ“Œ **This notebook has been updated in [jhj0517/finetuning-notebooks](https://github.com/jhj0517/finetuning-notebooks) repository!**\n",
        "\n",
        "## Version : 1.0.0\n",
        "---"
      ],
      "metadata": {
        "id": "doKhBBXIfS21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #(Optional) Check GPU\n",
        "\n",
        "#@markdown To convert model to a diffusers format 12GB VRAM is recommended.\n",
        "#@markdown <br>You can check your GPU setup before start.\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "23yZvUlagEsx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNbSbsctxahq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title #1. Install Dependencies\n",
        "#@markdown This notebook is powered by https://github.com/huggingface/diffusers\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "%cd diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 2. (Optional) Mount Google Drive\n",
        "\n",
        "#@markdown It's not mandatory but it's recommended to mount to Google Drive and use the Google Drive's path for your training image dataset.\n",
        "\n",
        "#@markdown The dataset should have following structure:\n",
        "\n",
        "#@markdown Each image file should have a corresponding text file (`.txt`) with the same name.\n",
        "#@markdown The text file contains prompts associated with the image.\n",
        "\n",
        "#@markdown ### Example File Structure:\n",
        "#@markdown ```\n",
        "#@markdown your-dataset/\n",
        "#@markdown â”œâ”€â”€ a (1).png         # Image file\n",
        "#@markdown â”œâ”€â”€ a (1).txt         # Corresponding prompt for a (1).png\n",
        "#@markdown â”œâ”€â”€ a (2).png         # Another image file\n",
        "#@markdown â”œâ”€â”€ a (2).txt         # Corresponding prompt for a (2).png\n",
        "#@markdown ```\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M1bu3MpsACOu",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce886cc-4844-4733-cfab-48ed436cd3be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 3-1) Flux -> Diffusers Converter\n",
        "#@markdown Set one of `CKPT_PATH` or `REPO_ID` for the model to be converted. Leave `REPO_ID` empty if you're using a local path.\n",
        "import os\n",
        "\n",
        "CKPT_PATH = \"\" # @param {type:\"string\"}\n",
        "# e. g.) black-forest-labs/FLUX.1-schnell\n",
        "REPO_ID = \"\" # @param {type:\"string\"}\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/finetuning-notebooks/diffusers/flux/model-name\"  # @param {type:\"string\"}\n",
        "DTYPE = \"bf16\" # @param {type:\"string\"}\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "command_parts = [\"python scripts/convert_flux_to_diffusers.py\"]\n",
        "\n",
        "if CKPT_PATH:\n",
        "    command_parts.append(f\"--ckpt_path {CKPT_PATH}\")\n",
        "if REPO_ID:\n",
        "    command_parts.append(f\"--original_state_dict_repo_id {REPO_ID}\")\n",
        "\n",
        "command_parts += [\n",
        "    \"--filename flux1-schnell.sft\",\n",
        "    f\"--output_path {OUTPUT_PATH}\",\n",
        "    \"--transformer\",\n",
        "    f\"--dtype {DTYPE}\"\n",
        "]\n",
        "\n",
        "command = \" \".join(command_parts)\n",
        "print(f\"Converting to transformer with: {command}\")\n",
        "!{command}\n",
        "\n",
        "\n",
        "command_parts = [\"python scripts/convert_flux_to_diffusers.py\"]\n",
        "\n",
        "if CKPT_PATH:\n",
        "    command_parts.append(f\"--ckpt_path {CKPT_PATH}\")\n",
        "if REPO_ID:\n",
        "    command_parts.append(f\"--original_state_dict_repo_id {REPO_ID}\")\n",
        "\n",
        "command_parts += [\n",
        "    \"--filename ae.sft\",\n",
        "    f\"--output_path {OUTPUT_PATH}\",\n",
        "    \"--vae\",\n",
        "    f\"--dtype {DTYPE}\"\n",
        "]\n",
        "\n",
        "print(f\"Converting to vae with: {command}\")\n",
        "!{command}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "t53q-Mx0UOMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 3-2) Hunyuan Video -> Diffusers Converter\n",
        "import os\n",
        "\n",
        "TRANSFORMER_PATH = \"\" # @param {type:\"string\"}\n",
        "VAE_PATH = \"\" # @param {type:\"string\"}\n",
        "TEXT_ENCODER_PATH = \"\" # @param {type:\"string\"}\n",
        "TOKENIZER_PATH = \"\" # @param {type:\"string\"}\n",
        "TEXT_ENCODER2_PATH = \"\" # @param {type:\"string\"}\n",
        "DTYPE = \"bf16\" # @param {type:\"string\"}\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/finetuning-notebooks/diffusers/hunyuan_video/model-name\"  # @param {type:\"string\"}\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "command_parts = [\"python scripts/convert_hunyuan_video_to_diffusers.py\"]\n",
        "\n",
        "command_parts += [\n",
        "    f\"--transformer_ckpt_path {TRANSFORMER_PATH}\",\n",
        "    f\"--vae_ckpt_path {VAE_PATH}\",\n",
        "    f\"--text_encoder_path {TEXT_ENCODER_PATH}\",\n",
        "    f\"--tokenizer_path {TOKENIZER_PATH}\",\n",
        "    f\"--text_encoder2_path {TEXT_ENCODER2_PATH}\",\n",
        "    f\"--output_path {OUTPUT_PATH}\",\n",
        "    f\"--dtype {DTYPE}\"\n",
        "]\n",
        "\n",
        "command = \" \".join(command_parts)\n",
        "print(f\"Converting to diffusers with: {command}\")\n",
        "!{command}\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FG2hN2UnkgV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 3-3) SD -> Diffusers Converter\n",
        "# https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "import os\n",
        "\n",
        "CKPT_PATH = \"\" # @param {type:\"string\"}\n",
        "VAE_PATH = \"\" # @param {type:\"string\"}\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/finetuning-notebooks/diffusers/sd/model-name\"  # @param {type:\"string\"}\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "command_parts = [\"python scripts/convert_original_stable_diffusion_to_diffusers.py\"]\n",
        "\n",
        "if VAE_PATH:\n",
        "    command_parts.append(f\"--VAE_PATH {VAE_PATH}\")\n",
        "\n",
        "command_parts += [\n",
        "    f\"--checkpoint_path {CKPT_PATH}\",\n",
        "    f\"--dump_path {OUTPUT_PATH}\"\n",
        "]\n",
        "\n",
        "command = \" \".join(command_parts)\n",
        "print(f\"Converting to diffusers with: {command}\")\n",
        "!{command}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wwUuM6b-k4L5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}