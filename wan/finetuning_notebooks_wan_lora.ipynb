{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "📌 **This notebook has been updated in [jhj0517/finetuning-notebooks](https://github.com/jhj0517/finetuning-notebooks) repository!**\n",
        "\n",
        "## Version : 1.0.0\n",
        "---"
      ],
      "metadata": {
        "id": "doKhBBXIfS21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #(Optional) Check GPU\n",
        "\n",
        "#@markdown To train Hunyuan Video lora 24GB VRAM is recommended.\n",
        "#@markdown  <br>If your dataset contains videos, then more than 24GB is recommended.\n",
        "#@markdown <br>You can check your GPU setup before start.\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "23yZvUlagEsx",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c24a9e-c194-4c04-db50-f754284ff3bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 25 23:03:47 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0             41W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kNbSbsctxahq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63c5b0c-c8de-4702-c5ed-131df822fb56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusion-pipe'...\n",
            "remote: Enumerating objects: 715, done.\u001b[K\n",
            "remote: Counting objects: 100% (272/272), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 715 (delta 243), reused 235 (delta 217), pack-reused 443 (from 1)\u001b[K\n",
            "Receiving objects: 100% (715/715), 7.80 MiB | 19.06 MiB/s, done.\n",
            "Resolving deltas: 100% (444/444), done.\n",
            "Submodule 'submodules/Cosmos' (https://github.com/NVIDIA/Cosmos) registered for path 'submodules/Cosmos'\n",
            "Submodule 'submodules/HunyuanVideo' (https://github.com/Tencent/HunyuanVideo) registered for path 'submodules/HunyuanVideo'\n",
            "Submodule 'submodules/Lumina_2' (https://github.com/Alpha-VLLM/Lumina-Image-2.0) registered for path 'submodules/Lumina_2'\n",
            "Cloning into '/content/diffusion-pipe/submodules/Cosmos'...\n",
            "remote: Enumerating objects: 392, done.        \n",
            "remote: Counting objects: 100% (115/115), done.        \n",
            "remote: Compressing objects: 100% (81/81), done.        \n",
            "remote: Total 392 (delta 63), reused 34 (delta 34), pack-reused 277 (from 1)        \n",
            "Receiving objects: 100% (392/392), 15.83 MiB | 42.55 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n",
            "Cloning into '/content/diffusion-pipe/submodules/HunyuanVideo'...\n",
            "remote: Enumerating objects: 775, done.        \n",
            "remote: Counting objects: 100% (483/483), done.        \n",
            "remote: Compressing objects: 100% (123/123), done.        \n",
            "remote: Total 775 (delta 423), reused 361 (delta 360), pack-reused 292 (from 1)        \n",
            "Receiving objects: 100% (775/775), 72.89 MiB | 48.75 MiB/s, done.\n",
            "Resolving deltas: 100% (478/478), done.\n",
            "Cloning into '/content/diffusion-pipe/submodules/Lumina_2'...\n",
            "remote: Enumerating objects: 141, done.        \n",
            "remote: Counting objects: 100% (50/50), done.        \n",
            "remote: Compressing objects: 100% (26/26), done.        \n",
            "remote: Total 141 (delta 47), reused 24 (delta 24), pack-reused 91 (from 2)        \n",
            "Receiving objects: 100% (141/141), 69.65 MiB | 47.99 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "Submodule path 'submodules/Cosmos': checked out 'a6e2fdd49053ae75836cedc2a99c7c84bc1c8c1b'\n",
            "Submodule path 'submodules/HunyuanVideo': checked out 'c4a9d7708dac7c930181c9e147d0092dffa36f92'\n",
            "Submodule path 'submodules/Lumina_2': checked out '09362957c2ce37407c7982fea742a8a72686b882'\n",
            "/content/diffusion-pipe\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.16.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed) (0.8.1)\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.1.0)\n",
            "Collecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.10.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed) (4.67.1)\n",
            "Collecting nvidia-ml-py (from deepspeed)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->deepspeed)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->deepspeed)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->deepspeed)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->deepspeed)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->deepspeed)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->deepspeed)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->deepspeed)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->deepspeed)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->deepspeed)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->deepspeed)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deepspeed) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->deepspeed) (3.0.2)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.16.4-py3-none-any.whl size=1562652 sha256=30a6dcf27ac4c20f5fa9a11790b3779261a1963f819b3a1440d3b207e2c2154f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/6c/e5/ccad75c8ade9cb21e74721affd6d17820b1806249aac34f7f0\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: nvidia-ml-py, hjson, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, deepspeed\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed deepspeed-0.16.4 hjson-3.1.0 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py-12.570.86 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting torch-optimi\n",
            "  Downloading torch_optimi-0.2.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from torch-optimi) (2.5.1+cu124)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from torch-optimi) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torch-optimi) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->torch-optimi) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->torch-optimi) (3.0.2)\n",
            "Downloading torch_optimi-0.2.1-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: torch-optimi\n",
            "Successfully installed torch-optimi-0.2.1\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.3\n",
            "Collecting av\n",
            "  Downloading av-14.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Downloading av-14.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-14.2.0\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n"
          ]
        }
      ],
      "source": [
        "#@title #1. Install Dependencies\n",
        "#@markdown This notebook is powered by https://github.com/tdrussell/diffusion-pipe\n",
        "!git clone --recurse-submodules https://github.com/tdrussell/diffusion-pipe\n",
        "%cd diffusion-pipe\n",
        "\n",
        "# Cherry picked dependencies to use in Colab.\n",
        "!pip install deepspeed\n",
        "!pip install datasets\n",
        "!pip install torch-optimi\n",
        "!pip install bitsandbytes\n",
        "!pip install av\n",
        "!pip install loguru\n",
        "!pip install flash-attn\n",
        "\n",
        "\n",
        "# Comment on the requirements above, and uncomment below if you're not using Colab.\n",
        "# !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126\n",
        "# !pip install deepspeed\n",
        "# !pip install toml\n",
        "# !pip install transformers\n",
        "# !pip install diffusers>=0.32.1\n",
        "# !pip install datasets\n",
        "# !pip install pillow\n",
        "# !pip install sentencepiece\n",
        "# !pip install protobuf\n",
        "# !pip install peft\n",
        "# !pip install torch-optimi\n",
        "# !pip install tensorboard\n",
        "# !pip install tqdm\n",
        "# !pip install safetensors\n",
        "# !pip install bitsandbytes\n",
        "# !pip install imageio[ffmpeg]\n",
        "# !pip install av\n",
        "# !pip install einops\n",
        "# !pip install accelerate\n",
        "# !pip install loguru\n",
        "# !pip install flash-attn; sys_platform==linux\n",
        "# !pip install omegaconf\n",
        "# !pip install iopath\n",
        "# !pip install termcolor\n",
        "# !pip install hydra-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 2. (Optional) Mount Google Drive\n",
        "\n",
        "#@markdown It's not mandatory but it's recommended to mount to Google Drive and use the Google Drive's path for your training dataset.\n",
        "\n",
        "#@markdown When training Hunyuan Lora, the dataset could contatin both images and videos.\n",
        "\n",
        "#@markdown Each file should have a corresponding text file (`.txt`) with the same name. <br>\n",
        "#@markdown **Each video must have a specific number of frames, as much as you will define later in \"frame_buckets\".**\n",
        "\n",
        "#@markdown The text file contains prompts associated with the video or image.\n",
        "\n",
        "\n",
        "#@markdown ### Example Dataset Structure:\n",
        "#@markdown ```\n",
        "#@markdown your-dataset/\n",
        "#@markdown ├── a (1).mp4         # Video file\n",
        "#@markdown ├── a (1).txt         # Corresponding prompt for a (1).mp4\n",
        "#@markdown ├── a (2).mp4         # Another video file\n",
        "#@markdown ├── a (2).txt         # Corresponding prompt for a (2).mp4\n",
        "#@markdown ├── a (3).png         # Image file\n",
        "#@markdown ├── a (3).txt         # Corresponding prompt for a (3).png\n",
        "#@markdown ```\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M1bu3MpsACOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "4519bc59-709f-4508-d1cf-22f5e4d80365"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not already contain files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c4d0be97d932>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WAN_VIDEO_URL = {\n",
        "    \"Wan2_1-T2V-1_3B_bf16.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\",\n",
        "    \"Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\",\n",
        "    \"Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\",\n",
        "}\n",
        "url = WAN_VIDEO_URL[\"Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\"]\n",
        "BASE_MODELS_DIR_PATH = \"/content/drive/MyDrive/finetuning-notebooks/wan/base_models\" # @param {type:\"string\"}\n",
        "\n",
        "!wget {url} -P {BASE_MODELS_DIR_PATH}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysexpFnuduo-",
        "outputId": "c8e86493-5235-41e1-e45a-94afe87fabcb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-25 23:37:34--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.88, 18.172.134.4, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/996dbad030df09b0b3c8e764f0fb5a81b98b220ab89524d6a9369e9ed882791f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors%3B+filename%3D%22Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors%22%3B&Expires=1740530254&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUzMDI1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvOTk2ZGJhZDAzMGRmMDliMGIzYzhlNzY0ZjBmYjVhODFiOThiMjIwYWI4OTUyNGQ2YTkzNjllOWVkODgyNzkxZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=QYg-97WggLVnPbDfoWQl9TMDrFX7JzhfUj6G2X%7EoIRf3jJ7z%7EprL9ttqKqjSzggJZrR291XgEXE0u4MiSIV-kLUmeaKStHWyYZsO47PB10KhO-7i2CDl7DHcgkBlyMYUqwqXJVH7RjzkquUtTPnVuRp8HAfeTZMJWnRdBKGij4yO22O-zq4SUP7F7WgoaDABsCpjnGN34MYy0nKYDokT75C0tEvjalpurV%7E0KwUb%7EK2WuIQ22l051Twbb1h7zh5P7gdxCDulupHf%7EcAyUkTNEwR0uDeYTM7B51OzZNpA%7E-nhIZ9OC3fOIK9qMRa4RJxDZr0Mh-crAlMQGIagav%7EcPQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-02-25 23:37:34--  https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/996dbad030df09b0b3c8e764f0fb5a81b98b220ab89524d6a9369e9ed882791f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors%3B+filename%3D%22Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors%22%3B&Expires=1740530254&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUzMDI1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvOTk2ZGJhZDAzMGRmMDliMGIzYzhlNzY0ZjBmYjVhODFiOThiMjIwYWI4OTUyNGQ2YTkzNjllOWVkODgyNzkxZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=QYg-97WggLVnPbDfoWQl9TMDrFX7JzhfUj6G2X%7EoIRf3jJ7z%7EprL9ttqKqjSzggJZrR291XgEXE0u4MiSIV-kLUmeaKStHWyYZsO47PB10KhO-7i2CDl7DHcgkBlyMYUqwqXJVH7RjzkquUtTPnVuRp8HAfeTZMJWnRdBKGij4yO22O-zq4SUP7F7WgoaDABsCpjnGN34MYy0nKYDokT75C0tEvjalpurV%7E0KwUb%7EK2WuIQ22l051Twbb1h7zh5P7gdxCDulupHf%7EcAyUkTNEwR0uDeYTM7B51OzZNpA%7E-nhIZ9OC3fOIK9qMRa4RJxDZr0Mh-crAlMQGIagav%7EcPQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.238.176.92, 18.238.176.83, 18.238.176.56, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.238.176.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16993877896 (16G) [binary/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors’\n",
            "\n",
            "Wan2_1-I2V-14B-480P 100%[===================>]  15.83G  41.6MB/s    in 6m 51s  \n",
            "\n",
            "2025-02-25 23:44:25 (39.4 MB/s) - ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors’ saved [16993877896/16993877896]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 3. (Optional) Register Huggingface Token To Download Base Model\n",
        "\n",
        "#@markdown This cell will download base models. If you don't already have the base model files in your google drive, run this.\n",
        "\n",
        "#@markdown You need Huggingface token (Read permission) to run this.\n",
        "\n",
        "#@markdown Get your tokens from https://huggingface.co/settings/tokens, and register in colab's seceret as **`HF_TOKEN`** and use it in any notebook. ( 'Read' permission is enough )\n",
        "\n",
        "#@markdown To register secrets in colab, click on the key-shaped icon in the left panel and enter your **`HF_TOKEN`** like this:\n",
        "\n",
        "#@markdown ![image](https://media.githubusercontent.com/media/jhj0517/finetuning-notebooks/master/docs/screenshots/colab_secrets.png)\n",
        "\n",
        "import huggingface_hub\n",
        "import os\n",
        "\n",
        "# Set params\n",
        "BASE_MODELS_DIR_PATH = \"/content/drive/MyDrive/finetuning-notebooks/wan/base_models\" # @param {type:\"string\"}\n",
        "WAN_VIDEO = \"Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\" #@param [\"Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\", \"Wan2_1-T2V-1_3B_bf16.safetensors\", \"Wan2_1-T2V-14B_fp8_e4m3fn.safetensors\", \"Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\", \"Wan2_1-I2V-14B-720P_fp8_e4m3fn.safetensors\"]\n",
        "VAE = \"Wan2_1_VAE_bf16.safetensors\" #@param [\"Wan2_1_VAE_bf16.safetensors\", \"Wan2_1_VAE_fp32.safetensors\"]\n",
        "CLIP = \"open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors\" #@param [\"open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors\"]\n",
        "LLM = \"umt5-xxl-enc-bf16.safetensors\" #@param [\"umt5-xxl-enc-bf16.safetensors\"]\n",
        "\n",
        "#@markdown Models will be downloaded from\n",
        "#@markdown - https://huggingface.co/Kijai/WanVideo_comfy\n",
        "\n",
        "WAN_VIDEO_URL = {\n",
        "    \"Wan2_1-T2V-1_3B_bf16.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\",\n",
        "    \"Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\",\n",
        "    \"Wan2_1-T2V-14B_fp8_e4m3fn.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-14B_fp8_e4m3fn.safetensors\",\n",
        "    \"Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors\",\n",
        "    \"Wan2_1-I2V-14B-720P_fp8_e4m3fn.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-I2V-14B-720P_fp8_e4m3fn.safetensors\",\n",
        "}\n",
        "\n",
        "WAN_VIDEO_VAE_URL = {\n",
        "    \"Wan2_1_VAE_bf16.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_bf16.safetensors\",\n",
        "    \"Wan2_1_VAE_fp32.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_fp32.safetensors\",\n",
        "}\n",
        "\n",
        "CLIP_URL = {\n",
        "    \"open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors\"\n",
        "}\n",
        "\n",
        "LLM_URL = {\n",
        "    \"umt5-xxl-enc-bf16.safetensors\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5-xxl-enc-bf16.safetensors\"\n",
        "}\n",
        "\n",
        "# Download models\n",
        "video_url, vae_url = WAN_VIDEO_URL[WAN_VIDEO], WAN_VIDEO_VAE_URL[VAE]\n",
        "clip_url, llm_url = CLIP_URL[CLIP], LLM_URL[LLM]\n",
        "\n",
        "!wget {video_url} -P {BASE_MODELS_DIR_PATH}\n",
        "!wget {vae_url} -P {BASE_MODELS_DIR_PATH}\n",
        "!wget {clip_url} -P {BASE_MODELS_DIR_PATH}\n",
        "!wget {llm_url} -P {BASE_MODELS_DIR_PATH}\n",
        "\n"
      ],
      "metadata": {
        "id": "9WzQRwZij5jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9cb752a-e15c-4076-b401-495be27de793"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-25 23:21:24--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.4, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/a913893ce03cd6e3d48853258f4521f054db6d72b59d67359ea0b138d8071812?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors%3B+filename%3D%22Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors%22%3B&Expires=1740529284&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUyOTI4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvYTkxMzg5M2NlMDNjZDZlM2Q0ODg1MzI1OGY0NTIxZjA1NGRiNmQ3MmI1OWQ2NzM1OWVhMGIxMzhkODA3MTgxMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=lCo8tiqBlUippHe1NPSOuwWYYQvGEr2lLosQSrRK1xcC721A1-aGCbQbnZ2nNSNyPIzEP0Tn4XN%7ESvcJReh%7EeGT5vSNIHdwYot0c%7Eoz8UM2ivl-OIW7NiSUs-tk0qZseeMPetge-tlDR-DebfrtDtEftMOc2rU%7EGPQAQ4lW%7ERLNGaBjUv8KbLl-oLphEQKB9SoiDMWvNjf6MoydLYvTVQDO2J9OqqslhrDTyoEiA4tjTLBQazS6CMYu49y%7E4mkpIiyjUauYOu9G-7EahivhPvTlNYTOJmx6rxThdnuBjW%7Eo7O3SYBUQ23pybt%7EsRHBEUUG9TTGs1Tbu9Z22S05vj4A__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-02-25 23:21:24--  https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/a913893ce03cd6e3d48853258f4521f054db6d72b59d67359ea0b138d8071812?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors%3B+filename%3D%22Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors%22%3B&Expires=1740529284&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUyOTI4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvYTkxMzg5M2NlMDNjZDZlM2Q0ODg1MzI1OGY0NTIxZjA1NGRiNmQ3MmI1OWQ2NzM1OWVhMGIxMzhkODA3MTgxMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=lCo8tiqBlUippHe1NPSOuwWYYQvGEr2lLosQSrRK1xcC721A1-aGCbQbnZ2nNSNyPIzEP0Tn4XN%7ESvcJReh%7EeGT5vSNIHdwYot0c%7Eoz8UM2ivl-OIW7NiSUs-tk0qZseeMPetge-tlDR-DebfrtDtEftMOc2rU%7EGPQAQ4lW%7ERLNGaBjUv8KbLl-oLphEQKB9SoiDMWvNjf6MoydLYvTVQDO2J9OqqslhrDTyoEiA4tjTLBQazS6CMYu49y%7E4mkpIiyjUauYOu9G-7EahivhPvTlNYTOJmx6rxThdnuBjW%7Eo7O3SYBUQ23pybt%7EsRHBEUUG9TTGs1Tbu9Z22S05vj4A__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.238.176.83, 18.238.176.91, 18.238.176.92, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.238.176.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1474162024 (1.4G) [binary/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors’\n",
            "\n",
            "Wan2_1-T2V-1_3B_fp8 100%[===================>]   1.37G  39.3MB/s    in 36s     \n",
            "\n",
            "2025-02-25 23:22:00 (39.2 MB/s) - ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors’ saved [1474162024/1474162024]\n",
            "\n",
            "--2025-02-25 23:22:00--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_bf16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.4, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/e027f6859a9c0f4dbfbaa9d1f27b1e5f371a5b8462e8d2d74c1ee8c44c20b1a8?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Wan2_1_VAE_bf16.safetensors%3B+filename%3D%22Wan2_1_VAE_bf16.safetensors%22%3B&Expires=1740529320&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUyOTMyMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvZTAyN2Y2ODU5YTljMGY0ZGJmYmFhOWQxZjI3YjFlNWYzNzFhNWI4NDYyZThkMmQ3NGMxZWU4YzQ0YzIwYjFhOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Es7q9%7EKwZDRuqYPcuAACjpEoYmgFAneNqjTuu89QAUOIfyAEOdGkJ6zzE6yiiDrWgaA8AJRkHwDU8u37N7Rcm1im2fxl-OSmeairGwKjSNKGPVPAZyUkKQDd5gHmgSJbf8cwA2bYQ9aWe31nr6zEbys9cxGKlMHEujxzQQoqiiYXbQ19z0SOvnPHcyX2jr4B1upaG4DxnPdGYDcF7HRlDOFzHUFtOcui0Mj0CscuFi0wCNSl50CWnjNl6qGKvfwzD091%7ETQ-vmrRPC28On2KB%7E%7ESA9SsxOLxdaXzbqLhLvC9G9oCFDnzndSifq0hnLY3iuygvk6McwHKCvgFAoV2IQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-02-25 23:22:00--  https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/e027f6859a9c0f4dbfbaa9d1f27b1e5f371a5b8462e8d2d74c1ee8c44c20b1a8?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Wan2_1_VAE_bf16.safetensors%3B+filename%3D%22Wan2_1_VAE_bf16.safetensors%22%3B&Expires=1740529320&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUyOTMyMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvZTAyN2Y2ODU5YTljMGY0ZGJmYmFhOWQxZjI3YjFlNWYzNzFhNWI4NDYyZThkMmQ3NGMxZWU4YzQ0YzIwYjFhOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Es7q9%7EKwZDRuqYPcuAACjpEoYmgFAneNqjTuu89QAUOIfyAEOdGkJ6zzE6yiiDrWgaA8AJRkHwDU8u37N7Rcm1im2fxl-OSmeairGwKjSNKGPVPAZyUkKQDd5gHmgSJbf8cwA2bYQ9aWe31nr6zEbys9cxGKlMHEujxzQQoqiiYXbQ19z0SOvnPHcyX2jr4B1upaG4DxnPdGYDcF7HRlDOFzHUFtOcui0Mj0CscuFi0wCNSl50CWnjNl6qGKvfwzD091%7ETQ-vmrRPC28On2KB%7E%7ESA9SsxOLxdaXzbqLhLvC9G9oCFDnzndSifq0hnLY3iuygvk6McwHKCvgFAoV2IQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.160.225.120, 18.160.225.72, 18.160.225.13, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.160.225.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253807438 (242M) [binary/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/Wan2_1_VAE_bf16.safetensors’\n",
            "\n",
            "Wan2_1_VAE_bf16.saf 100%[===================>] 242.05M  40.5MB/s    in 6.0s    \n",
            "\n",
            "2025-02-25 23:22:06 (40.4 MB/s) - ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/Wan2_1_VAE_bf16.safetensors’ saved [253807438/253807438]\n",
            "\n",
            "--2025-02-25 23:22:06--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.88, 18.172.134.24, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/875648f9bc6d9f7a9364f4c0cf5fb728dbc57f5e35b4dfb14114a8ec0cae041d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors%3B+filename%3D%22open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors%22%3B&Expires=1740529326&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUyOTMyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvODc1NjQ4ZjliYzZkOWY3YTkzNjRmNGMwY2Y1ZmI3MjhkYmM1N2Y1ZTM1YjRkZmIxNDExNGE4ZWMwY2FlMDQxZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=lNu1kfzQfZ954Z2X5VDQ%7EiPa--4htQJT32QA3tF2Xrl24CJyiu9-cbX-A6rfN1XT3IdxBLqnwoDnVwCCXlJAjNuQ7jRPIFAy84tk2SC03AcomOhnwbEoEEzjcVJiWpykvVLVfBH13EYRL-FPc9O9akoORgyqccDnrbOUDSB-YkmlSWQ7CDSiQvy4dhoiDs2a3LTvX0GI%7EJ6xQCG3gHTtE7Q56%7EIHGCufps2QWg15IXmS605%7EuwF%7EI3WHG5UaMemZiMjkL-ZpYR034f%7EMhmQTUkm7WmVAqWUzGu03MGKn5YmLDPQeBxVKT15jOeMoq36ExJ5T96c5tHtQkBTuZvHeEQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-02-25 23:22:06--  https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/875648f9bc6d9f7a9364f4c0cf5fb728dbc57f5e35b4dfb14114a8ec0cae041d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors%3B+filename%3D%22open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors%22%3B&Expires=1740529326&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUyOTMyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvODc1NjQ4ZjliYzZkOWY3YTkzNjRmNGMwY2Y1ZmI3MjhkYmM1N2Y1ZTM1YjRkZmIxNDExNGE4ZWMwY2FlMDQxZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=lNu1kfzQfZ954Z2X5VDQ%7EiPa--4htQJT32QA3tF2Xrl24CJyiu9-cbX-A6rfN1XT3IdxBLqnwoDnVwCCXlJAjNuQ7jRPIFAy84tk2SC03AcomOhnwbEoEEzjcVJiWpykvVLVfBH13EYRL-FPc9O9akoORgyqccDnrbOUDSB-YkmlSWQ7CDSiQvy4dhoiDs2a3LTvX0GI%7EJ6xQCG3gHTtE7Q56%7EIHGCufps2QWg15IXmS605%7EuwF%7EI3WHG5UaMemZiMjkL-ZpYR034f%7EMhmQTUkm7WmVAqWUzGu03MGKn5YmLDPQeBxVKT15jOeMoq36ExJ5T96c5tHtQkBTuZvHeEQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.160.225.120, 18.160.225.72, 18.160.225.13, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.160.225.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2386112002 (2.2G) [binary/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors’\n",
            "\n",
            "open-clip-xlm-rober 100%[===================>]   2.22G  39.9MB/s    in 57s     \n",
            "\n",
            "2025-02-25 23:23:04 (39.7 MB/s) - ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors’ saved [2386112002/2386112002]\n",
            "\n",
            "--2025-02-25 23:23:04--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5-xxl-enc-bf16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.176.103, 18.238.176.129, 18.238.176.8, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.176.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/4fa971faf306cad919033d5bbe192e571dc08452f800cbf2ec3c73977c01b2cc?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27umt5-xxl-enc-bf16.safetensors%3B+filename%3D%22umt5-xxl-enc-bf16.safetensors%22%3B&Expires=1740529384&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUyOTM4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvNGZhOTcxZmFmMzA2Y2FkOTE5MDMzZDViYmUxOTJlNTcxZGMwODQ1MmY4MDBjYmYyZWMzYzczOTc3YzAxYjJjYz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=iOdLp8VlQx281XiwJ8D%7Ey0zMZ8Rjqdj6LItW6ng6go%7EHhhrGps0FJgvJJVjHn5wrfvGiwhQ70X6hZfvq0jDnQZtL4whA-H26sROemgHXHbYlSkUpPHfliIFLXiLb7V-40zl18rRrWbIHLdnC5svf0raojAX4TFIiFXNvVIkXL7od1qybRQyz6rZqAfSoL8F5R2vvdnma5gcR9WSIYlswQhCEF4Z1qTViFxvaJxLNV0aFt5lHRVM9QQrFt30hRjDfkQPtl2uGWxTvJ2rCJyxzXV8x5IfD7ciNspeoyS%7ENAGA49Ix3wcEppptBl1D0vx9F9uVXYAPAp0etH7AEbQEGJA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-02-25 23:23:04--  https://cdn-lfs-us-1.hf.co/repos/6a/f7/6af72071ed19a24fd36436ce0baf194019423c9eaa7c8b82f2fa5f3ac60c31b6/4fa971faf306cad919033d5bbe192e571dc08452f800cbf2ec3c73977c01b2cc?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27umt5-xxl-enc-bf16.safetensors%3B+filename%3D%22umt5-xxl-enc-bf16.safetensors%22%3B&Expires=1740529384&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUyOTM4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzZhL2Y3LzZhZjcyMDcxZWQxOWEyNGZkMzY0MzZjZTBiYWYxOTQwMTk0MjNjOWVhYTdjOGI4MmYyZmE1ZjNhYzYwYzMxYjYvNGZhOTcxZmFmMzA2Y2FkOTE5MDMzZDViYmUxOTJlNTcxZGMwODQ1MmY4MDBjYmYyZWMzYzczOTc3YzAxYjJjYz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=iOdLp8VlQx281XiwJ8D%7Ey0zMZ8Rjqdj6LItW6ng6go%7EHhhrGps0FJgvJJVjHn5wrfvGiwhQ70X6hZfvq0jDnQZtL4whA-H26sROemgHXHbYlSkUpPHfliIFLXiLb7V-40zl18rRrWbIHLdnC5svf0raojAX4TFIiFXNvVIkXL7od1qybRQyz6rZqAfSoL8F5R2vvdnma5gcR9WSIYlswQhCEF4Z1qTViFxvaJxLNV0aFt5lHRVM9QQrFt30hRjDfkQPtl2uGWxTvJ2rCJyxzXV8x5IfD7ciNspeoyS%7ENAGA49Ix3wcEppptBl1D0vx9F9uVXYAPAp0etH7AEbQEGJA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.170.152.55, 3.170.152.105, 3.170.152.28, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.170.152.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11361845464 (11G) [binary/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/umt5-xxl-enc-bf16.safetensors’\n",
            "\n",
            "umt5-xxl-enc-bf16.s 100%[===================>]  10.58G  40.0MB/s    in 4m 32s  \n",
            "\n",
            "2025-02-25 23:27:35 (39.9 MB/s) - ‘/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/umt5-xxl-enc-bf16.safetensors’ saved [11361845464/11361845464]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 4. Train with Parameters\n",
        "import os\n",
        "import sys\n",
        "import toml\n",
        "\n",
        "#@markdown If you're intended to train Lora from previous checkpoint, check this.\n",
        "RESUME_FROM_CHECKPOINT = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ## Paths Configuration\n",
        "OUTPUT_LORA_NAME = \"My-Wan-Lora-V1\" # @param {type:\"string\"}\n",
        "OUTPUT_LORA_DIR_PATH = \"/content/drive/MyDrive/finetuning-notebooks/wan/outputs\"  # @param {type:\"string\"}\n",
        "BASE_WAN_VIDEO_PATH = \"/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\" # @param {type:\"string\"}\n",
        "BASE_VAE_PATH = \"/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/Wan2_1_VAE_bf16.safetensors\" # @param {type:\"string\"}\n",
        "BASE_CLIP_PATH = \"/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/open-clip-xlm-roberta-large-vit-huge-14_fp16.safetensors\" # @param {type:\"string\"}\n",
        "BASE_LLM_PATH = \"/content/drive/MyDrive/finetuning-notebooks/wan/base_models/wan/umt5-xxl-enc-bf16.safetensors\" # @param {type:\"string\"}\n",
        "DATASET_PATH = \"/content/drive/MyDrive/finetuning-notebooks/dataset/dog-prompt\" # @param {type:\"string\"}\n",
        "\n",
        "OUTPUT_LORA_DIR_PATH = os.path.join(OUTPUT_LORA_DIR_PATH, OUTPUT_LORA_NAME)\n",
        "\n",
        "#@markdown ## Dataset Configuration\n",
        "#@markdown - **`frame_buckets`** is the list of frame numbers in your dataset.\n",
        "#@markdown <br>For example, if your dataset contains 30, 60 frames of videos, then use : [30, 60]\n",
        "#@markdown <br>Don't use too long frames unless you don't have a lot of VRAM.\n",
        "#@markdown <br>If your dataset also contains images, then use : [1, 30, 60]\n",
        "#@markdown - **`resolutions`** is the list of resolutions which **`diffusion-pipe`** will resize your dataset.\n",
        "#@markdown <br>**`diffusion-pipe`** is smart to handle resizing your dataset by 1:2 or 2:1 image etc.\n",
        "#@markdown <br>If you have less than 24GB of VRAM, just set it to 512, then increase it according to your device.\n",
        "## Frame Buckets Settings\n",
        "frame_buckets = [1]  # @param {type:\"raw\"}\n",
        "# You can use 1024 if you have 24 GB > VRAM.\n",
        "resolutions = [512]  # @param {type:\"raw\"}\n",
        "## Aspect Ratio Bucketing Settings\n",
        "enable_ar_bucket = True  # @param {type:\"boolean\"}\n",
        "min_ar = 0.5  # @param {type:\"number\"}\n",
        "max_ar = 2.0  # @param {type:\"number\"}\n",
        "num_ar_buckets = 7  # @param {type:\"integer\"}\n",
        "# Reduce as necessary\n",
        "num_repeats = 5\n",
        "\n",
        "# Write dataset.toml\n",
        "dataset_config = {\n",
        "    \"resolutions\": resolutions,\n",
        "    \"frame_buckets\": frame_buckets,\n",
        "\n",
        "    \"enable_ar_bucket\": enable_ar_bucket,\n",
        "    \"min_ar\": min_ar,\n",
        "    \"max_ar\": max_ar,\n",
        "    \"num_ar_buckets\": num_ar_buckets,\n",
        "    \"directory\": [\n",
        "        {\n",
        "            \"path\": DATASET_PATH,\n",
        "            \"num_repeats\": num_repeats,\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "\n",
        "os.makedirs(OUTPUT_LORA_DIR_PATH, exist_ok=True)\n",
        "os.makedirs(DATASET_PATH, exist_ok=True)\n",
        "dataset_config_file_path = os.path.join(DATASET_PATH, \"dataset.toml\")\n",
        "with open(dataset_config_file_path, \"w\") as toml_file:\n",
        "    toml.dump(dataset_config, toml_file)\n",
        "print(f\"dataset.toml is saved to {dataset_config_file_path}\")\n",
        "\n",
        "#@markdown ## Base Model Configuration\n",
        "\n",
        "model_type = 'hunyuan-video'\n",
        "dtype = 'bfloat16'  # @param {type:\"string\"}\n",
        "transformer_dtype = 'float8'  # @param {type:\"string\"}\n",
        "timestep_sample_method = 'logit_normal'  # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Training Settings\n",
        "epochs = 50  # @param {type:\"integer\"}\n",
        "# Batch size of a single forward/backward pass for one GPU.\n",
        "micro_batch_size_per_gpu = 1  # @param {type:\"integer\"}\n",
        "# Pipeline parallelism degree. A single instance of the model is divided across this many GPUs.\n",
        "pipeline_stages = 1  # @param {type:\"integer\"}\n",
        "gradient_accumulation_steps = 4  # @param {type:\"integer\"}\n",
        "gradient_clipping = 1.0  # @param {type:\"number\"}\n",
        "# Learning rate warmup.\n",
        "warmup_steps = 50  # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown ## Eval Settings\n",
        "eval_every_n_epochs = 1  # @param {type:\"integer\"}\n",
        "eval_before_first_step = True  # @param {type:\"boolean\"}\n",
        "eval_micro_batch_size_per_gpu = 1  # @param {type:\"integer\"}\n",
        "eval_gradient_accumulation_steps = 1  # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown ## Lora Settings\n",
        "adapter_type = 'lora'\n",
        "rank = 32  # @param {type:\"integer\"}\n",
        "adapter_dtype = 'bfloat16'  # @param {type:\"string\"}\n",
        "\n",
        "# Optimizer settings\n",
        "optimizer_type = 'adamw_optimi'  # @param {type:\"string\"}\n",
        "lr = 2e-5  # @param {type:\"number\"}\n",
        "betas = [0.9, 0.99]  # @param {type:\"raw\"}\n",
        "weight_decay = 0.02  # @param {type:\"number\"}\n",
        "eps = 1e-8  # @param {type:\"number\"}\n",
        "\n",
        "#@markdown ## Misc Settings\n",
        "save_every_n_epochs = 10  # @param {type:\"integer\"}\n",
        "checkpoint_every_n_minutes = 30  # @param {type:\"integer\"}\n",
        "activation_checkpointing = True  # @param {type:\"boolean\"}\n",
        "partition_method = 'parameters'  # @param {type:\"string\"}\n",
        "save_dtype = 'bfloat16'  # @param {type:\"string\"}\n",
        "caching_batch_size = 1  # @param {type:\"integer\"}\n",
        "steps_per_print = 1  # @param {type:\"integer\"}\n",
        "video_clip_mode = 'single_middle'  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# Write config.toml\n",
        "train_config = {\n",
        "    \"output_dir\": OUTPUT_LORA_DIR_PATH,\n",
        "    \"dataset\": dataset_config_file_path,\n",
        "\n",
        "    # Training Settings\n",
        "    \"epochs\": epochs,\n",
        "    \"micro_batch_size_per_gpu\": micro_batch_size_per_gpu,\n",
        "    \"pipeline_stages\": pipeline_stages,\n",
        "    \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "    \"gradient_clipping\": gradient_clipping,\n",
        "    \"warmup_steps\": warmup_steps,\n",
        "\n",
        "    # Eval Settings\n",
        "    \"eval_every_n_epochs\": eval_every_n_epochs,\n",
        "    \"eval_before_first_step\": eval_before_first_step,\n",
        "    \"eval_micro_batch_size_per_gpu\": eval_micro_batch_size_per_gpu,\n",
        "    \"eval_gradient_accumulation_steps\": eval_gradient_accumulation_steps,\n",
        "\n",
        "    # Misc Settings\n",
        "    \"save_every_n_epochs\": save_every_n_epochs,\n",
        "    \"checkpoint_every_n_minutes\": checkpoint_every_n_minutes,\n",
        "    \"activation_checkpointing\": activation_checkpointing,\n",
        "    \"partition_method\": partition_method,\n",
        "    \"save_dtype\": save_dtype,\n",
        "    \"caching_batch_size\": caching_batch_size,\n",
        "    \"steps_per_print\": steps_per_print,\n",
        "    \"video_clip_mode\": video_clip_mode,\n",
        "\n",
        "    \"model\": {\n",
        "        \"type\": model_type,\n",
        "        \"transformer_path\": BASE_WAN_VIDEO_PATH,\n",
        "        \"vae_path\": BASE_VAE_PATH,\n",
        "        \"llm_path\": BASE_LLM_PATH,\n",
        "        \"clip_path\": BASE_CLIP_PATH,\n",
        "        \"dtype\": dtype,\n",
        "        \"transformer_dtype\": transformer_dtype,\n",
        "        \"timestep_sample_method\": timestep_sample_method,\n",
        "    },\n",
        "\n",
        "    \"adapter\": {\n",
        "        \"type\": \"lora\",\n",
        "        \"rank\": rank,\n",
        "        \"dtype\": adapter_dtype,\n",
        "    },\n",
        "\n",
        "    \"optimizer\": {\n",
        "        \"type\": optimizer_type,\n",
        "        \"lr\": lr,\n",
        "        \"betas\": betas,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"eps\": eps,\n",
        "    },\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "train_config_file_path = os.path.join(DATASET_PATH, \"config.toml\")\n",
        "with open(train_config_file_path, \"w\") as toml_file:\n",
        "    toml.dump(train_config, toml_file)\n",
        "print(f\"config.toml is saved to {train_config_file_path}\")\n",
        "\n",
        "\n",
        "## Train\n",
        "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
        "os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
        "\n",
        "if RESUME_FROM_CHECKPOINT:\n",
        "  !deepspeed --num_gpus=1 train.py --deepspeed --config {train_config_file_path} --resume_from_checkpoint\n",
        "else:\n",
        "  !deepspeed --num_gpus=1 train.py --deepspeed --config {train_config_file_path}\n"
      ],
      "metadata": {
        "id": "fob2cRMQeW5C",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56d6459-a937-41b6-b0f7-883b635db3cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.toml is saved to /content/drive/MyDrive/finetuning-notebooks/dataset/dog-prompt/dataset.toml\n",
            "config.toml is saved to /content/drive/MyDrive/finetuning-notebooks/dataset/dog-prompt/config.toml\n",
            "[2025-02-25 23:46:02,657] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-02-25 23:46:11.946150: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-02-25 23:46:11.963104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740527171.985396   11780 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740527171.992115   11780 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-25 23:46:12.015002: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-02-25 23:46:15,166] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2025-02-25 23:46:15,167] [INFO] [runner.py:607:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed --config /content/drive/MyDrive/finetuning-notebooks/dataset/dog-prompt/config.toml\n",
            "[2025-02-25 23:46:17,003] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-02-25 23:46:21.115243: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740527181.136689   11908 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740527181.143249   11908 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NCCL_P2P_DISABLE=1\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.22.3-1\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NCCL_IB_DISABLE=1\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2025-02-25 23:46:24,182] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2025-02-25 23:46:24,183] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2025-02-25 23:46:24,183] [INFO] [launch.py:164:main] dist_world_size=1\n",
            "[2025-02-25 23:46:24,183] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2025-02-25 23:46:24,183] [INFO] [launch.py:256:main] process 12012 spawned with command: ['/usr/bin/python3', '-u', 'train.py', '--local_rank=0', '--deepspeed', '--config', '/content/drive/MyDrive/finetuning-notebooks/dataset/dog-prompt/config.toml']\n",
            "[2025-02-25 23:46:25,996] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-02-25 23:46:30.346817: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740527190.369016   12012 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740527190.375660   12012 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-02-25 23:46:34,691] [INFO] [comm.py:658:init_distributed] cdb=None\n",
            "[2025-02-25 23:46:34,692] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/diffusion-pipe/train.py\", line 214, in <module>\n",
            "[rank0]:     model = hunyuan_video.HunyuanVideoPipeline(config)\n",
            "[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/diffusion-pipe/models/hunyuan_video.py\", line 226, in __init__\n",
            "[rank0]:     vae.load_state_dict(vae_sd)\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2584, in load_state_dict\n",
            "[rank0]:     raise RuntimeError(\n",
            "[rank0]: RuntimeError: Error(s) in loading state_dict for AutoencoderKLCausal3D:\n",
            "[rank0]: \tMissing key(s) in state_dict: \"encoder.conv_in.conv.weight\", \"encoder.conv_in.conv.bias\", \"encoder.down_blocks.0.resnets.0.norm1.weight\", \"encoder.down_blocks.0.resnets.0.norm1.bias\", \"encoder.down_blocks.0.resnets.0.conv1.conv.weight\", \"encoder.down_blocks.0.resnets.0.conv1.conv.bias\", \"encoder.down_blocks.0.resnets.0.norm2.weight\", \"encoder.down_blocks.0.resnets.0.norm2.bias\", \"encoder.down_blocks.0.resnets.0.conv2.conv.weight\", \"encoder.down_blocks.0.resnets.0.conv2.conv.bias\", \"encoder.down_blocks.0.resnets.1.norm1.weight\", \"encoder.down_blocks.0.resnets.1.norm1.bias\", \"encoder.down_blocks.0.resnets.1.conv1.conv.weight\", \"encoder.down_blocks.0.resnets.1.conv1.conv.bias\", \"encoder.down_blocks.0.resnets.1.norm2.weight\", \"encoder.down_blocks.0.resnets.1.norm2.bias\", \"encoder.down_blocks.0.resnets.1.conv2.conv.weight\", \"encoder.down_blocks.0.resnets.1.conv2.conv.bias\", \"encoder.down_blocks.0.downsamplers.0.conv.conv.weight\", \"encoder.down_blocks.0.downsamplers.0.conv.conv.bias\", \"encoder.down_blocks.1.resnets.0.norm1.weight\", \"encoder.down_blocks.1.resnets.0.norm1.bias\", \"encoder.down_blocks.1.resnets.0.conv1.conv.weight\", \"encoder.down_blocks.1.resnets.0.conv1.conv.bias\", \"encoder.down_blocks.1.resnets.0.norm2.weight\", \"encoder.down_blocks.1.resnets.0.norm2.bias\", \"encoder.down_blocks.1.resnets.0.conv2.conv.weight\", \"encoder.down_blocks.1.resnets.0.conv2.conv.bias\", \"encoder.down_blocks.1.resnets.0.conv_shortcut.conv.weight\", \"encoder.down_blocks.1.resnets.0.conv_shortcut.conv.bias\", \"encoder.down_blocks.1.resnets.1.norm1.weight\", \"encoder.down_blocks.1.resnets.1.norm1.bias\", \"encoder.down_blocks.1.resnets.1.conv1.conv.weight\", \"encoder.down_blocks.1.resnets.1.conv1.conv.bias\", \"encoder.down_blocks.1.resnets.1.norm2.weight\", \"encoder.down_blocks.1.resnets.1.norm2.bias\", \"encoder.down_blocks.1.resnets.1.conv2.conv.weight\", \"encoder.down_blocks.1.resnets.1.conv2.conv.bias\", \"encoder.down_blocks.1.downsamplers.0.conv.conv.weight\", \"encoder.down_blocks.1.downsamplers.0.conv.conv.bias\", \"encoder.down_blocks.2.resnets.0.norm1.weight\", \"encoder.down_blocks.2.resnets.0.norm1.bias\", \"encoder.down_blocks.2.resnets.0.conv1.conv.weight\", \"encoder.down_blocks.2.resnets.0.conv1.conv.bias\", \"encoder.down_blocks.2.resnets.0.norm2.weight\", \"encoder.down_blocks.2.resnets.0.norm2.bias\", \"encoder.down_blocks.2.resnets.0.conv2.conv.weight\", \"encoder.down_blocks.2.resnets.0.conv2.conv.bias\", \"encoder.down_blocks.2.resnets.0.conv_shortcut.conv.weight\", \"encoder.down_blocks.2.resnets.0.conv_shortcut.conv.bias\", \"encoder.down_blocks.2.resnets.1.norm1.weight\", \"encoder.down_blocks.2.resnets.1.norm1.bias\", \"encoder.down_blocks.2.resnets.1.conv1.conv.weight\", \"encoder.down_blocks.2.resnets.1.conv1.conv.bias\", \"encoder.down_blocks.2.resnets.1.norm2.weight\", \"encoder.down_blocks.2.resnets.1.norm2.bias\", \"encoder.down_blocks.2.resnets.1.conv2.conv.weight\", \"encoder.down_blocks.2.resnets.1.conv2.conv.bias\", \"encoder.down_blocks.2.downsamplers.0.conv.conv.weight\", \"encoder.down_blocks.2.downsamplers.0.conv.conv.bias\", \"encoder.down_blocks.3.resnets.0.norm1.weight\", \"encoder.down_blocks.3.resnets.0.norm1.bias\", \"encoder.down_blocks.3.resnets.0.conv1.conv.weight\", \"encoder.down_blocks.3.resnets.0.conv1.conv.bias\", \"encoder.down_blocks.3.resnets.0.norm2.weight\", \"encoder.down_blocks.3.resnets.0.norm2.bias\", \"encoder.down_blocks.3.resnets.0.conv2.conv.weight\", \"encoder.down_blocks.3.resnets.0.conv2.conv.bias\", \"encoder.down_blocks.3.resnets.1.norm1.weight\", \"encoder.down_blocks.3.resnets.1.norm1.bias\", \"encoder.down_blocks.3.resnets.1.conv1.conv.weight\", \"encoder.down_blocks.3.resnets.1.conv1.conv.bias\", \"encoder.down_blocks.3.resnets.1.norm2.weight\", \"encoder.down_blocks.3.resnets.1.norm2.bias\", \"encoder.down_blocks.3.resnets.1.conv2.conv.weight\", \"encoder.down_blocks.3.resnets.1.conv2.conv.bias\", \"encoder.mid_block.attentions.0.group_norm.weight\", \"encoder.mid_block.attentions.0.group_norm.bias\", \"encoder.mid_block.attentions.0.to_q.weight\", \"encoder.mid_block.attentions.0.to_q.bias\", \"encoder.mid_block.attentions.0.to_k.weight\", \"encoder.mid_block.attentions.0.to_k.bias\", \"encoder.mid_block.attentions.0.to_v.weight\", \"encoder.mid_block.attentions.0.to_v.bias\", \"encoder.mid_block.attentions.0.to_out.0.weight\", \"encoder.mid_block.attentions.0.to_out.0.bias\", \"encoder.mid_block.resnets.0.norm1.weight\", \"encoder.mid_block.resnets.0.norm1.bias\", \"encoder.mid_block.resnets.0.conv1.conv.weight\", \"encoder.mid_block.resnets.0.conv1.conv.bias\", \"encoder.mid_block.resnets.0.norm2.weight\", \"encoder.mid_block.resnets.0.norm2.bias\", \"encoder.mid_block.resnets.0.conv2.conv.weight\", \"encoder.mid_block.resnets.0.conv2.conv.bias\", \"encoder.mid_block.resnets.1.norm1.weight\", \"encoder.mid_block.resnets.1.norm1.bias\", \"encoder.mid_block.resnets.1.conv1.conv.weight\", \"encoder.mid_block.resnets.1.conv1.conv.bias\", \"encoder.mid_block.resnets.1.norm2.weight\", \"encoder.mid_block.resnets.1.norm2.bias\", \"encoder.mid_block.resnets.1.conv2.conv.weight\", \"encoder.mid_block.resnets.1.conv2.conv.bias\", \"encoder.conv_norm_out.weight\", \"encoder.conv_norm_out.bias\", \"encoder.conv_out.conv.weight\", \"encoder.conv_out.conv.bias\", \"decoder.conv_in.conv.weight\", \"decoder.conv_in.conv.bias\", \"decoder.up_blocks.0.resnets.0.norm1.weight\", \"decoder.up_blocks.0.resnets.0.norm1.bias\", \"decoder.up_blocks.0.resnets.0.conv1.conv.weight\", \"decoder.up_blocks.0.resnets.0.conv1.conv.bias\", \"decoder.up_blocks.0.resnets.0.norm2.weight\", \"decoder.up_blocks.0.resnets.0.norm2.bias\", \"decoder.up_blocks.0.resnets.0.conv2.conv.weight\", \"decoder.up_blocks.0.resnets.0.conv2.conv.bias\", \"decoder.up_blocks.0.resnets.1.norm1.weight\", \"decoder.up_blocks.0.resnets.1.norm1.bias\", \"decoder.up_blocks.0.resnets.1.conv1.conv.weight\", \"decoder.up_blocks.0.resnets.1.conv1.conv.bias\", \"decoder.up_blocks.0.resnets.1.norm2.weight\", \"decoder.up_blocks.0.resnets.1.norm2.bias\", \"decoder.up_blocks.0.resnets.1.conv2.conv.weight\", \"decoder.up_blocks.0.resnets.1.conv2.conv.bias\", \"decoder.up_blocks.0.resnets.2.norm1.weight\", \"decoder.up_blocks.0.resnets.2.norm1.bias\", \"decoder.up_blocks.0.resnets.2.conv1.conv.weight\", \"decoder.up_blocks.0.resnets.2.conv1.conv.bias\", \"decoder.up_blocks.0.resnets.2.norm2.weight\", \"decoder.up_blocks.0.resnets.2.norm2.bias\", \"decoder.up_blocks.0.resnets.2.conv2.conv.weight\", \"decoder.up_blocks.0.resnets.2.conv2.conv.bias\", \"decoder.up_blocks.0.upsamplers.0.conv.conv.weight\", \"decoder.up_blocks.0.upsamplers.0.conv.conv.bias\", \"decoder.up_blocks.1.resnets.0.norm1.weight\", \"decoder.up_blocks.1.resnets.0.norm1.bias\", \"decoder.up_blocks.1.resnets.0.conv1.conv.weight\", \"decoder.up_blocks.1.resnets.0.conv1.conv.bias\", \"decoder.up_blocks.1.resnets.0.norm2.weight\", \"decoder.up_blocks.1.resnets.0.norm2.bias\", \"decoder.up_blocks.1.resnets.0.conv2.conv.weight\", \"decoder.up_blocks.1.resnets.0.conv2.conv.bias\", \"decoder.up_blocks.1.resnets.1.norm1.weight\", \"decoder.up_blocks.1.resnets.1.norm1.bias\", \"decoder.up_blocks.1.resnets.1.conv1.conv.weight\", \"decoder.up_blocks.1.resnets.1.conv1.conv.bias\", \"decoder.up_blocks.1.resnets.1.norm2.weight\", \"decoder.up_blocks.1.resnets.1.norm2.bias\", \"decoder.up_blocks.1.resnets.1.conv2.conv.weight\", \"decoder.up_blocks.1.resnets.1.conv2.conv.bias\", \"decoder.up_blocks.1.resnets.2.norm1.weight\", \"decoder.up_blocks.1.resnets.2.norm1.bias\", \"decoder.up_blocks.1.resnets.2.conv1.conv.weight\", \"decoder.up_blocks.1.resnets.2.conv1.conv.bias\", \"decoder.up_blocks.1.resnets.2.norm2.weight\", \"decoder.up_blocks.1.resnets.2.norm2.bias\", \"decoder.up_blocks.1.resnets.2.conv2.conv.weight\", \"decoder.up_blocks.1.resnets.2.conv2.conv.bias\", \"decoder.up_blocks.1.upsamplers.0.conv.conv.weight\", \"decoder.up_blocks.1.upsamplers.0.conv.conv.bias\", \"decoder.up_blocks.2.resnets.0.norm1.weight\", \"decoder.up_blocks.2.resnets.0.norm1.bias\", \"decoder.up_blocks.2.resnets.0.conv1.conv.weight\", \"decoder.up_blocks.2.resnets.0.conv1.conv.bias\", \"decoder.up_blocks.2.resnets.0.norm2.weight\", \"decoder.up_blocks.2.resnets.0.norm2.bias\", \"decoder.up_blocks.2.resnets.0.conv2.conv.weight\", \"decoder.up_blocks.2.resnets.0.conv2.conv.bias\", \"decoder.up_blocks.2.resnets.0.conv_shortcut.conv.weight\", \"decoder.up_blocks.2.resnets.0.conv_shortcut.conv.bias\", \"decoder.up_blocks.2.resnets.1.norm1.weight\", \"decoder.up_blocks.2.resnets.1.norm1.bias\", \"decoder.up_blocks.2.resnets.1.conv1.conv.weight\", \"decoder.up_blocks.2.resnets.1.conv1.conv.bias\", \"decoder.up_blocks.2.resnets.1.norm2.weight\", \"decoder.up_blocks.2.resnets.1.norm2.bias\", \"decoder.up_blocks.2.resnets.1.conv2.conv.weight\", \"decoder.up_blocks.2.resnets.1.conv2.conv.bias\", \"decoder.up_blocks.2.resnets.2.norm1.weight\", \"decoder.up_blocks.2.resnets.2.norm1.bias\", \"decoder.up_blocks.2.resnets.2.conv1.conv.weight\", \"decoder.up_blocks.2.resnets.2.conv1.conv.bias\", \"decoder.up_blocks.2.resnets.2.norm2.weight\", \"decoder.up_blocks.2.resnets.2.norm2.bias\", \"decoder.up_blocks.2.resnets.2.conv2.conv.weight\", \"decoder.up_blocks.2.resnets.2.conv2.conv.bias\", \"decoder.up_blocks.2.upsamplers.0.conv.conv.weight\", \"decoder.up_blocks.2.upsamplers.0.conv.conv.bias\", \"decoder.up_blocks.3.resnets.0.norm1.weight\", \"decoder.up_blocks.3.resnets.0.norm1.bias\", \"decoder.up_blocks.3.resnets.0.conv1.conv.weight\", \"decoder.up_blocks.3.resnets.0.conv1.conv.bias\", \"decoder.up_blocks.3.resnets.0.norm2.weight\", \"decoder.up_blocks.3.resnets.0.norm2.bias\", \"decoder.up_blocks.3.resnets.0.conv2.conv.weight\", \"decoder.up_blocks.3.resnets.0.conv2.conv.bias\", \"decoder.up_blocks.3.resnets.0.conv_shortcut.conv.weight\", \"decoder.up_blocks.3.resnets.0.conv_shortcut.conv.bias\", \"decoder.up_blocks.3.resnets.1.norm1.weight\", \"decoder.up_blocks.3.resnets.1.norm1.bias\", \"decoder.up_blocks.3.resnets.1.conv1.conv.weight\", \"decoder.up_blocks.3.resnets.1.conv1.conv.bias\", \"decoder.up_blocks.3.resnets.1.norm2.weight\", \"decoder.up_blocks.3.resnets.1.norm2.bias\", \"decoder.up_blocks.3.resnets.1.conv2.conv.weight\", \"decoder.up_blocks.3.resnets.1.conv2.conv.bias\", \"decoder.up_blocks.3.resnets.2.norm1.weight\", \"decoder.up_blocks.3.resnets.2.norm1.bias\", \"decoder.up_blocks.3.resnets.2.conv1.conv.weight\", \"decoder.up_blocks.3.resnets.2.conv1.conv.bias\", \"decoder.up_blocks.3.resnets.2.norm2.weight\", \"decoder.up_blocks.3.resnets.2.norm2.bias\", \"decoder.up_blocks.3.resnets.2.conv2.conv.weight\", \"decoder.up_blocks.3.resnets.2.conv2.conv.bias\", \"decoder.mid_block.attentions.0.group_norm.weight\", \"decoder.mid_block.attentions.0.group_norm.bias\", \"decoder.mid_block.attentions.0.to_q.weight\", \"decoder.mid_block.attentions.0.to_q.bias\", \"decoder.mid_block.attentions.0.to_k.weight\", \"decoder.mid_block.attentions.0.to_k.bias\", \"decoder.mid_block.attentions.0.to_v.weight\", \"decoder.mid_block.attentions.0.to_v.bias\", \"decoder.mid_block.attentions.0.to_out.0.weight\", \"decoder.mid_block.attentions.0.to_out.0.bias\", \"decoder.mid_block.resnets.0.norm1.weight\", \"decoder.mid_block.resnets.0.norm1.bias\", \"decoder.mid_block.resnets.0.conv1.conv.weight\", \"decoder.mid_block.resnets.0.conv1.conv.bias\", \"decoder.mid_block.resnets.0.norm2.weight\", \"decoder.mid_block.resnets.0.norm2.bias\", \"decoder.mid_block.resnets.0.conv2.conv.weight\", \"decoder.mid_block.resnets.0.conv2.conv.bias\", \"decoder.mid_block.resnets.1.norm1.weight\", \"decoder.mid_block.resnets.1.norm1.bias\", \"decoder.mid_block.resnets.1.conv1.conv.weight\", \"decoder.mid_block.resnets.1.conv1.conv.bias\", \"decoder.mid_block.resnets.1.norm2.weight\", \"decoder.mid_block.resnets.1.norm2.bias\", \"decoder.mid_block.resnets.1.conv2.conv.weight\", \"decoder.mid_block.resnets.1.conv2.conv.bias\", \"decoder.conv_norm_out.weight\", \"decoder.conv_norm_out.bias\", \"decoder.conv_out.conv.weight\", \"decoder.conv_out.conv.bias\", \"quant_conv.weight\", \"quant_conv.bias\", \"post_quant_conv.weight\", \"post_quant_conv.bias\". \n",
            "[rank0]: \tUnexpected key(s) in state_dict: \"model.conv1.bias\", \"model.conv1.weight\", \"model.conv2.bias\", \"model.conv2.weight\", \"model.decoder.conv1.bias\", \"model.decoder.conv1.weight\", \"model.decoder.head.0.gamma\", \"model.decoder.head.2.bias\", \"model.decoder.head.2.weight\", \"model.decoder.middle.0.residual.0.gamma\", \"model.decoder.middle.0.residual.2.bias\", \"model.decoder.middle.0.residual.2.weight\", \"model.decoder.middle.0.residual.3.gamma\", \"model.decoder.middle.0.residual.6.bias\", \"model.decoder.middle.0.residual.6.weight\", \"model.decoder.middle.1.norm.gamma\", \"model.decoder.middle.1.proj.bias\", \"model.decoder.middle.1.proj.weight\", \"model.decoder.middle.1.to_qkv.bias\", \"model.decoder.middle.1.to_qkv.weight\", \"model.decoder.middle.2.residual.0.gamma\", \"model.decoder.middle.2.residual.2.bias\", \"model.decoder.middle.2.residual.2.weight\", \"model.decoder.middle.2.residual.3.gamma\", \"model.decoder.middle.2.residual.6.bias\", \"model.decoder.middle.2.residual.6.weight\", \"model.decoder.upsamples.0.residual.0.gamma\", \"model.decoder.upsamples.0.residual.2.bias\", \"model.decoder.upsamples.0.residual.2.weight\", \"model.decoder.upsamples.0.residual.3.gamma\", \"model.decoder.upsamples.0.residual.6.bias\", \"model.decoder.upsamples.0.residual.6.weight\", \"model.decoder.upsamples.1.residual.0.gamma\", \"model.decoder.upsamples.1.residual.2.bias\", \"model.decoder.upsamples.1.residual.2.weight\", \"model.decoder.upsamples.1.residual.3.gamma\", \"model.decoder.upsamples.1.residual.6.bias\", \"model.decoder.upsamples.1.residual.6.weight\", \"model.decoder.upsamples.10.residual.0.gamma\", \"model.decoder.upsamples.10.residual.2.bias\", \"model.decoder.upsamples.10.residual.2.weight\", \"model.decoder.upsamples.10.residual.3.gamma\", \"model.decoder.upsamples.10.residual.6.bias\", \"model.decoder.upsamples.10.residual.6.weight\", \"model.decoder.upsamples.11.resample.1.bias\", \"model.decoder.upsamples.11.resample.1.weight\", \"model.decoder.upsamples.12.residual.0.gamma\", \"model.decoder.upsamples.12.residual.2.bias\", \"model.decoder.upsamples.12.residual.2.weight\", \"model.decoder.upsamples.12.residual.3.gamma\", \"model.decoder.upsamples.12.residual.6.bias\", \"model.decoder.upsamples.12.residual.6.weight\", \"model.decoder.upsamples.13.residual.0.gamma\", \"model.decoder.upsamples.13.residual.2.bias\", \"model.decoder.upsamples.13.residual.2.weight\", \"model.decoder.upsamples.13.residual.3.gamma\", \"model.decoder.upsamples.13.residual.6.bias\", \"model.decoder.upsamples.13.residual.6.weight\", \"model.decoder.upsamples.14.residual.0.gamma\", \"model.decoder.upsamples.14.residual.2.bias\", \"model.decoder.upsamples.14.residual.2.weight\", \"model.decoder.upsamples.14.residual.3.gamma\", \"model.decoder.upsamples.14.residual.6.bias\", \"model.decoder.upsamples.14.residual.6.weight\", \"model.decoder.upsamples.2.residual.0.gamma\", \"model.decoder.upsamples.2.residual.2.bias\", \"model.decoder.upsamples.2.residual.2.weight\", \"model.decoder.upsamples.2.residual.3.gamma\", \"model.decoder.upsamples.2.residual.6.bias\", \"model.decoder.upsamples.2.residual.6.weight\", \"model.decoder.upsamples.3.resample.1.bias\", \"model.decoder.upsamples.3.resample.1.weight\", \"model.decoder.upsamples.3.time_conv.bias\", \"model.decoder.upsamples.3.time_conv.weight\", \"model.decoder.upsamples.4.residual.0.gamma\", \"model.decoder.upsamples.4.residual.2.bias\", \"model.decoder.upsamples.4.residual.2.weight\", \"model.decoder.upsamples.4.residual.3.gamma\", \"model.decoder.upsamples.4.residual.6.bias\", \"model.decoder.upsamples.4.residual.6.weight\", \"model.decoder.upsamples.4.shortcut.bias\", \"model.decoder.upsamples.4.shortcut.weight\", \"model.decoder.upsamples.5.residual.0.gamma\", \"model.decoder.upsamples.5.residual.2.bias\", \"model.decoder.upsamples.5.residual.2.weight\", \"model.decoder.upsamples.5.residual.3.gamma\", \"model.decoder.upsamples.5.residual.6.bias\", \"model.decoder.upsamples.5.residual.6.weight\", \"model.decoder.upsamples.6.residual.0.gamma\", \"model.decoder.upsamples.6.residual.2.bias\", \"model.decoder.upsamples.6.residual.2.weight\", \"model.decoder.upsamples.6.residual.3.gamma\", \"model.decoder.upsamples.6.residual.6.bias\", \"model.decoder.upsamples.6.residual.6.weight\", \"model.decoder.upsamples.7.resample.1.bias\", \"model.decoder.upsamples.7.resample.1.weight\", \"model.decoder.upsamples.7.time_conv.bias\", \"model.decoder.upsamples.7.time_conv.weight\", \"model.decoder.upsamples.8.residual.0.gamma\", \"model.decoder.upsamples.8.residual.2.bias\", \"model.decoder.upsamples.8.residual.2.weight\", \"model.decoder.upsamples.8.residual.3.gamma\", \"model.decoder.upsamples.8.residual.6.bias\", \"model.decoder.upsamples.8.residual.6.weight\", \"model.decoder.upsamples.9.residual.0.gamma\", \"model.decoder.upsamples.9.residual.2.bias\", \"model.decoder.upsamples.9.residual.2.weight\", \"model.decoder.upsamples.9.residual.3.gamma\", \"model.decoder.upsamples.9.residual.6.bias\", \"model.decoder.upsamples.9.residual.6.weight\", \"model.encoder.conv1.bias\", \"model.encoder.conv1.weight\", \"model.encoder.downsamples.0.residual.0.gamma\", \"model.encoder.downsamples.0.residual.2.bias\", \"model.encoder.downsamples.0.residual.2.weight\", \"model.encoder.downsamples.0.residual.3.gamma\", \"model.encoder.downsamples.0.residual.6.bias\", \"model.encoder.downsamples.0.residual.6.weight\", \"model.encoder.downsamples.1.residual.0.gamma\", \"model.encoder.downsamples.1.residual.2.bias\", \"model.encoder.downsamples.1.residual.2.weight\", \"model.encoder.downsamples.1.residual.3.gamma\", \"model.encoder.downsamples.1.residual.6.bias\", \"model.encoder.downsamples.1.residual.6.weight\", \"model.encoder.downsamples.10.residual.0.gamma\", \"model.encoder.downsamples.10.residual.2.bias\", \"model.encoder.downsamples.10.residual.2.weight\", \"model.encoder.downsamples.10.residual.3.gamma\", \"model.encoder.downsamples.10.residual.6.bias\", \"model.encoder.downsamples.10.residual.6.weight\", \"model.encoder.downsamples.2.resample.1.bias\", \"model.encoder.downsamples.2.resample.1.weight\", \"model.encoder.downsamples.3.residual.0.gamma\", \"model.encoder.downsamples.3.residual.2.bias\", \"model.encoder.downsamples.3.residual.2.weight\", \"model.encoder.downsamples.3.residual.3.gamma\", \"model.encoder.downsamples.3.residual.6.bias\", \"model.encoder.downsamples.3.residual.6.weight\", \"model.encoder.downsamples.3.shortcut.bias\", \"model.encoder.downsamples.3.shortcut.weight\", \"model.encoder.downsamples.4.residual.0.gamma\", \"model.encoder.downsamples.4.residual.2.bias\", \"model.encoder.downsamples.4.residual.2.weight\", \"model.encoder.downsamples.4.residual.3.gamma\", \"model.encoder.downsamples.4.residual.6.bias\", \"model.encoder.downsamples.4.residual.6.weight\", \"model.encoder.downsamples.5.resample.1.bias\", \"model.encoder.downsamples.5.resample.1.weight\", \"model.encoder.downsamples.5.time_conv.bias\", \"model.encoder.downsamples.5.time_conv.weight\", \"model.encoder.downsamples.6.residual.0.gamma\", \"model.encoder.downsamples.6.residual.2.bias\", \"model.encoder.downsamples.6.residual.2.weight\", \"model.encoder.downsamples.6.residual.3.gamma\", \"model.encoder.downsamples.6.residual.6.bias\", \"model.encoder.downsamples.6.residual.6.weight\", \"model.encoder.downsamples.6.shortcut.bias\", \"model.encoder.downsamples.6.shortcut.weight\", \"model.encoder.downsamples.7.residual.0.gamma\", \"model.encoder.downsamples.7.residual.2.bias\", \"model.encoder.downsamples.7.residual.2.weight\", \"model.encoder.downsamples.7.residual.3.gamma\", \"model.encoder.downsamples.7.residual.6.bias\", \"model.encoder.downsamples.7.residual.6.weight\", \"model.encoder.downsamples.8.resample.1.bias\", \"model.encoder.downsamples.8.resample.1.weight\", \"model.encoder.downsamples.8.time_conv.bias\", \"model.encoder.downsamples.8.time_conv.weight\", \"model.encoder.downsamples.9.residual.0.gamma\", \"model.encoder.downsamples.9.residual.2.bias\", \"model.encoder.downsamples.9.residual.2.weight\", \"model.encoder.downsamples.9.residual.3.gamma\", \"model.encoder.downsamples.9.residual.6.bias\", \"model.encoder.downsamples.9.residual.6.weight\", \"model.encoder.head.0.gamma\", \"model.encoder.head.2.bias\", \"model.encoder.head.2.weight\", \"model.encoder.middle.0.residual.0.gamma\", \"model.encoder.middle.0.residual.2.bias\", \"model.encoder.middle.0.residual.2.weight\", \"model.encoder.middle.0.residual.3.gamma\", \"model.encoder.middle.0.residual.6.bias\", \"model.encoder.middle.0.residual.6.weight\", \"model.encoder.middle.1.norm.gamma\", \"model.encoder.middle.1.proj.bias\", \"model.encoder.middle.1.proj.weight\", \"model.encoder.middle.1.to_qkv.bias\", \"model.encoder.middle.1.to_qkv.weight\", \"model.encoder.middle.2.residual.0.gamma\", \"model.encoder.middle.2.residual.2.bias\", \"model.encoder.middle.2.residual.2.weight\", \"model.encoder.middle.2.residual.3.gamma\", \"model.encoder.middle.2.residual.6.bias\", \"model.encoder.middle.2.residual.6.weight\". \n",
            "[rank0]:[W225 23:46:38.294858514 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "[2025-02-25 23:46:40,186] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 12012\n",
            "[2025-02-25 23:46:40,186] [ERROR] [launch.py:325:sigkill_handler] ['/usr/bin/python3', '-u', 'train.py', '--local_rank=0', '--deepspeed', '--config', '/content/drive/MyDrive/finetuning-notebooks/dataset/dog-prompt/config.toml'] exits with return code = 1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}